problem_file: data/cuda_problems_033125.jsonl   # Input problems
sample_file: data/ans_samples.5.jsonl          # Generated samples

model: llama-3.1-nemotron-70b-instruct                      # Model to use
num_samples_per_problem: 5          # Samples to generate per problem

# params:
#   temperature: 0.5
#   top_p: 0.8
#   max_tokens: 1024


# custom_model:
#   api_endpoint: https://integrate.api.nvidia.com/v1
#   model_id: nvidia/llama-3.1-nemotron-70b-instruct
